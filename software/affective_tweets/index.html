<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.5.0 for Hugo"><meta name=author content="OpenCENIA"><meta name=description content="AffectiveTweets is a WEKA package for analyzing emotion and sentiment of English written tweets."><link rel=alternate hreflang=en-us href=https://opencenia.github.io/software/affective_tweets/><meta name=theme-color content="#1565c0"><link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.4567f1e7ae6323c1cc6a69d4783ef0ff.css><link rel=alternate href=/software/affective_tweets/index.xml type=application/rss+xml title=OpenCENIA><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hua0c6be8cf0f9f8b69c1b584196d369ff_113001_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hua0c6be8cf0f9f8b69c1b584196d369ff_113001_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://opencenia.github.io/software/affective_tweets/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@cen_ia"><meta property="twitter:creator" content="@cen_ia"><meta property="og:site_name" content="OpenCENIA"><meta property="og:url" content="https://opencenia.github.io/software/affective_tweets/"><meta property="og:title" content="AffectiveTweets | OpenCENIA"><meta property="og:description" content="AffectiveTweets is a WEKA package for analyzing emotion and sentiment of English written tweets."><meta property="og:image" content="https://opencenia.github.io/media/logo_huadb352de640ebaad14838e8a393df198_92131_300x300_fit_lanczos_3.png"><meta property="twitter:image" content="https://opencenia.github.io/media/logo_huadb352de640ebaad14838e8a393df198_92131_300x300_fit_lanczos_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2016-04-27T00:00:00+00:00"><title>AffectiveTweets | OpenCENIA</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=3ca2e8940ee978483ba23b7a886eec88><script src=/js/wowchemy-init.min.2ed908358299dd7ab553faae685c746c.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/><img src=/media/logo_huadb352de640ebaad14838e8a393df198_92131_0x70_resize_lanczos_3.png alt=OpenCENIA></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/><img src=/media/logo_huadb352de640ebaad14838e8a393df198_92131_0x70_resize_lanczos_3.png alt=OpenCENIA></a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/software><span>Software</span></a></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Models</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/models/nlp><span>NLP</span></a>
<a class=dropdown-item href=/models/vision><span>Vision</span></a></div></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Data</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/data/datasets><span>Datasets</span></a>
<a class=dropdown-item href=/data/shared_tasks><span>Shared Tasks</span></a>
<a class=dropdown-item href=/data/benchmarks><span>Benchmarks</span></a></div></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Education</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/education/courses><span>Courses</span></a>
<a class=dropdown-item href=/education/talks><span>Talks</span></a>
<a class=dropdown-item href=/education/podcast><span>Podcast</span></a>
<a class=dropdown-item href=/education/tutorials><span>Tutorials</span></a>
<a class=dropdown-item href=/education/demos><span>Interactive Demos</span></a></div></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class="universal-wrapper pt-3"><h1>AffectiveTweets</h1></div><div class=universal-wrapper><div class=article-style><h2 id=about>About</h2><p><a href=http://weka.sourceforge.net/packageMetaData/AffectiveTweets/index.html target=_blank rel=noopener>AffectiveTweets</a> is a <a href=http://www.cs.waikato.ac.nz/~ml/weka/ target=_blank rel=noopener>WEKA</a> package for analyzing emotion and sentiment of tweets. The source code is hosted on <a href=https://github.com/felipebravom/AffectiveTweets target=_blank rel=noopener>Github</a>.</p><p>The package implements WEKA filters for calculating state-of-the-art affective analysis features from tweets that can be fed into machine learning algorithms. Many of these features were drawn from the <a href=http://saifmohammad.com/WebPages/NRC-Canada-Sentiment.htm target=_blank rel=noopener>NRC-Canada System</a>. It also implements methods for building affective lexicons and distant supervision methods for training affective models from unlabelled tweets.</p><p>Description about the filters, installation instructions, and examples are given below.</p><h2 id=official-baseline-system>Official Baseline System</h2><p>The package was made available as the official baseline system for the <a href=http://optima.jrc.it/wassa2017/ target=_blank rel=noopener>WASSA-2017</a> Shared Task on Emotion Intensity <a href=http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html target=_blank rel=noopener>(EmoInt)</a> and for <a href=http://alt.qcri.org/semeval2018/ target=_blank rel=noopener>SemEval-2018</a> Task 1: <a href=http://www.saifmohammad.com/WebPages/affectintweets.htm target=_blank rel=noopener>Affect in Tweets</a>.</p><p>Five participating teams used AffectiveTweets in WASSA-2017 to generate feature vectors, including the teams that eventually ranked first, second, and third. For SemEval-2018, the package was used by 15 teams.</p><h2 id=relevant-papers>Relevant Papers</h2><p>The most relevant papers on which this package is based are:</p><ul><li><p><a href=http://saifmohammad.com/WebDocs/NRC-Sentiment-JAIR-2014.pdf target=_blank rel=noopener>Sentiment Analysis of Short Informal Texts</a>. Svetlana Kiritchenko, Xiaodan Zhu and Saif Mohammad. Journal of Artificial Intelligence Research, volume 50, pages 723-762, August 2014. <a href=http://saifmohammad.com/WebDocs/JAIR14-bibtex.txt target=_blank rel=noopener>BibTeX</a></p></li><li><p><a href=http://www.sciencedirect.com/science/article/pii/S0950705114002068 target=_blank rel=noopener>Meta-Level Sentiment Models for Big Social Data Analysis</a>. F. Bravo-Marquez, M. Mendoza and B. Poblete. Knowledge-Based Systems Volume 69, October 2014, Pages 86–99. <a href=http://dblp.uni-trier.de/rec/bib2/journals/kbs/Bravo-MarquezMP14.bib target=_blank rel=noopener>BibTex</a></p></li><li><p><a href=http://saifmohammad.com/WebDocs/1605.01655v1.pdf target=_blank rel=noopener>Stance and sentiment in tweets</a>. Saif M. Mohammad, Parinaz Sobhani, and Svetlana Kiritchenko. 2017. Special Section of the ACM Transactions on Internet Technology on Argumentation in Social Media 17(3). <a href=http://saifmohammad.com/WebPages/Abstracts/stance-toit.bib.txt target=_blank rel=noopener>BibTeX</a></p></li><li><p><a href="http://dl.acm.org/citation.cfm?id=2336261" target=_blank rel=noopener>Sentiment strength detection for the social Web</a>. Thelwall, M., Buckley, K., & Paltoglou, G. (2012). Journal of the American Society for Information Science and Technology, 63(1), 163-173. <a href=http://dblp.uni-trier.de/rec/bib2/journals/jasis/ThelwallBP12.bib target=_blank rel=noopener>BibTex</a></p></li></ul><h2 id=citation>Citation</h2><p>Please cite the following paper if using this package in an academic publication:</p><ul><li>F. Bravo-Marquez, E. Frank, B. Pfahringer, and S. M. Mohammad <a href=http://jmlr.org/papers/v20/18-450.html target=_blank rel=noopener>AffectiveTweets: a WEKA Package for Analyzing Affect in Tweets</a>, In <em>Journal of Machine Learning Research</em> Volume 20(92), pages 1−6, 2019. (<a href=https://felipebravom.com/publications/jmlr2019.pdf target=_blank rel=noopener>pdf</a>)</li></ul><p>You are also welcome to cite a previous publication describing the package:</p><ul><li>S. M. Mohammad and F. Bravo-Marquez <a href=http://anthology.aclweb.org/S/S17/S17-1007.pdf target=_blank rel=noopener>Emotion Intensities in Tweets</a>, In **Sem &lsquo;17: Proceedings of the sixth joint conference on lexical and computational semantics (*Sem)*, August 2017, Vancouver, Canada. (<a href=https://felipebravom.com/publications/starsem2017.pdf target=_blank rel=noopener>pdf</a>)</li></ul><p>You should also cite the papers describing any of the lexicons or resources you are using with this package.</p><ul><li><p>Here is the <a href=fullBio.bib.txt>BibTex</a> entry for the package along with the entries for the resources listed below.</p></li><li><p>Here is the <a href=shortBio.bib.txt>BibTex</a> entry just for the package.</p></li></ul><p>The individual references for each resource can be found through the links provided below.</p><h3 id=filters>Filters</h3><h4 id=tweet-level-filters>Tweet-level Filters</h4><ol><li><p><strong>TweetToSparseFeatureVector</strong>: calculates sparse features, such as word and character n-grams from tweets. There are parameters for filtering out infrequent features e.g., (n-grams occurring in less than <em>m</em> tweets) and for setting the weighting approach (boolean or frequency based).</p><ul><li><strong>Word n-grams</strong>: extracts word n-grams from <em>n</em>=1 to a maximum value.<ul><li><strong>Negations</strong>: add a prefix to words occurring in negated contexts, e.g., I don&rsquo;t like you => I don&rsquo;t NEG-like NEG-you. The prefixes only affect word n-gram features. The scope of negation finishes with the next punctuation expression <em>([\.|,|:|;|!|\?]+)</em> .</li></ul></li><li><strong>Character n-grams</strong>: calculates character n-grams.</li><li><strong>POS tags</strong>: tags tweets using the <a href=http://www.cs.cmu.edu/~ark/TweetNLP/ target=_blank rel=noopener>CMU Tweet NLP tool</a>, and creates a vector space model based on the sequence of POS tags. <a href=http://dblp.uni-trier.de/rec/bib2/conf/acl/GimpelSODMEHYFS11.bib target=_blank rel=noopener>BibTex</a></li><li><strong>Brown clusters</strong>: maps the words in a tweet to Brown word clusters and creates a low-dimensional vector space model. It can be used with n-grams of word clusters. The word clusters are also taken from the <a href=http://www.cs.cmu.edu/~ark/TweetNLP/ target=_blank rel=noopener>CMU Tweet NLP tool</a>.</li></ul></li><li><p><strong>TweetToLexiconFeatureVector</strong>: calculates features from a tweet using several lexicons.</p><ul><li><a href=http://mpqa.cs.pitt.edu/lexicons/subj_lexicon target=_blank rel=noopener>MPQA</a>: counts the number of positive and negative words from the MPQA subjectivity lexicon. <a href=http://dblp.uni-trier.de/rec/bib2/conf/naacl/WilsonWH05.bib target=_blank rel=noopener>BibTex</a></li><li><a href=https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon target=_blank rel=noopener>Bing Liu</a>: counts the number of positive and negative words from the Bing Liu lexicon. <a href=http://dblp.uni-trier.de/rec/bib2/conf/kdd/HuL04.bib target=_blank rel=noopener>BibTex</a></li><li><a href=https://github.com/fnielsen/afinn target=_blank rel=noopener>AFINN</a>: calculates positive and negative variables by aggregating the positive and negative word scores provided by this lexicon. <a href=http://dblp.uni-trier.de/rec/bib2/conf/msm/Nielsen11.bib target=_blank rel=noopener>BibTex</a></li><li><a href=http://saifmohammad.com/WebPages/lexicons.html#NRCTwitter target=_blank rel=noopener>Sentiment140</a>: calculates positive and negative variables by aggregating the positive and negative word scores provided by this lexicon created with tweets annotated by emoticons. <a href=http://saifmohammad.com/WebDocs/JAIR14-bibtex.txt target=_blank rel=noopener>BibTex</a></li><li><a href=http://saifmohammad.com/WebPages/lexicons.html#NRCTwitter target=_blank rel=noopener>NRC Hashtag Sentiment lexicon</a>: calculates positive and negative variables by aggregating the positive and negative word scores provided by this lexicon created with tweets annotated with emotional hashtags. <a href=http://saifmohammad.com/WebDocs/JAIR14-bibtex.txt target=_blank rel=noopener>BibTex</a></li><li><a href=http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm target=_blank rel=noopener>NRC Word-Emotion Association Lexicon</a>: counts the number of words matching each emotion from this lexicon. <a href=http://saifmohammad.com/WebPages/Abstracts/crowdemo.bib.txt target=_blank rel=noopener>BibTex</a></li><li><a href=http://www.cs.waikato.ac.nz/ml/sa/lex.html#emolextwitter target=_blank rel=noopener>NRC-10 Expanded</a>: adds the emotion associations of the words matching the Twitter Specific expansion of the NRC Word-Emotion Association Lexicon. <a href=http://dblp.uni-trier.de/rec/bib2/conf/webi/Bravo-MarquezFM16.bib target=_blank rel=noopener>BibTex</a></li><li><a href=http://saifmohammad.com/WebPages/lexicons.html#HashEmo target=_blank rel=noopener>NRC Hashtag Emotion Association Lexicon</a>: adds the emotion associations of the words matching this lexicon. <a href=http://saifmohammad.com/WebPages/hashtagPersonality-bib.html target=_blank rel=noopener>BibTex</a></li><li><a href=http://sentiwordnet.isti.cnr.it target=_blank rel=noopener>SentiWordNet</a>: calculates positive and negative scores using SentiWordnet. We calculate a weighted average of the sentiment distributions of the synsets for word occurring in multiple synsets. The weights correspond to the reciprocal ranks of the senses in order to give higher weights to most popular senses. <a href=http://dblp.uni-trier.de/rec/bib2/conf/lrec/BaccianellaES10.bib target=_blank rel=noopener>BibTex</a></li><li><a href=https://github.com/fnielsen/afinn target=_blank rel=noopener>Emoticons</a>: calculates a positive and a negative score by aggregating the word associations provided by a list of emoticons. The list is taken from the <a href=https://github.com/fnielsen/afinn target=_blank rel=noopener>AFINN</a> project.</li><li>Negations: counts the number of negating words in the tweet.</li></ul></li><li><p><strong>TweetToInputLexiconFeatureVector</strong>: calculates features from a tweet using a given list of affective lexicons, where each lexicon is represented as an <a href=https://weka.wikispaces.com/ARFF target=_blank rel=noopener>ARFF</a> file. The features are calculated by adding or counting the affective associations of the words matching the given lexicons. All numeric and nominal attributes from each lexicon are considered. Numeric scores are added and nominal are counted. The <a href=http://www.saifmohammad.com/WebPages/AffectIntensity.htm target=_blank rel=noopener>NRC-Affect-Intensity</a> lexicon is used by deault. <a href=http://dblp.uni-trier.de/rec/bib2/journals/corr/Mohammad17.bib target=_blank rel=noopener>BibTex</a></p></li><li><p><strong>TweetToSentiStrengthFeatureVector</strong>: calculates positive and negative sentiment strengths for a tweet using <a href=http://sentistrength.wlv.ac.uk/ target=_blank rel=noopener>SentiStrength</a>. Disclaimer: <strong>SentiStrength</strong> can only be used for academic purposes from within this package. <a href=http://dblp.uni-trier.de/rec/bib2/journals/jasis/ThelwallBP12.bib target=_blank rel=noopener>BibTex</a></p></li><li><p><strong>TweetToEmbeddingsFeatureVector</strong>: calculates a tweet-level feature representation using pre-trained word embeddings. A dummy word-embedding formed by zeroes is used for word with no corresponding embedding. The tweet vectors can be calculated using the following schemes:</p><ul><li>Average word embeddings.</li><li>Add word embeddings.</li><li>Concatenation of first <em>k</em> embeddings. Dummy values are added if the tweet has less than <em>k</em> words.</li></ul></li><li><p><strong>TweetNLPPOSTagger</strong>: runs the Twitter-specific POS tagger from the CMU TweetNLP library on the given tweets. POS tags are prepended to the tokens.</p></li></ol><h4 id=word-level-filters>Word-level Filters</h4><ol><li><p><strong>PMILexiconExpander</strong>: calculates the Pointwise Mutual Information (PMI) semantic orientation for each word in a corpus of tweets annotated by sentiment. The score is calculated by subtracting the PMI of the target word with a negative sentiment from the PMI of the target word with a positive sentiment. This is a supervised filter. <a href=http://dblp.uni-trier.de/rec/bib2/conf/acl/Turney02.bib target=_blank rel=noopener>BibTex</a></p></li><li><p><strong>TweetCentroid</strong>: calculates word distributional vectors from a corpus of unlabelled tweets by treating them as the centroid of the tweet vectors in which they appear. The vectors can be labelled using an affective lexicon to train a word-level affective classifier. This classifier can be used to expand the original lexicon. <a href=http://dblp.uni-trier.de/rec/bib2/conf/sigir/Bravo-MarquezFP15.bib target=_blank rel=noopener>BibTex</a>, <a href=http://www.cs.waikato.ac.nz/~fbravoma/publications/sigir15.pdf target=_blank rel=noopener>original paper</a></p></li><li><p><strong>LabelWordVectors</strong>: labels word vectors with an input lexicon in arff format. This filter is useful for training word-level affective classifiers.</p></li></ol><h3 id=distant-supervision-filters>Distant Supervision Filters</h3><ol><li><p><strong>ASA</strong>: Annotate-Sample-Average (ASA) is a lexicon-based distant supervision method for training polarity classifiers in Twitter in the absence of labelled data. It takes a collection of unlabelled tweets and a polarity lexicon in arff format and creates synthetic labelled instances. Each labelled instance is created by sampling with replacement a number of tweets containing at least one word from the lexicon with the desired polarity, and averaging the feature vectors of the sampled tweets. <a href=http://dblp.uni-trier.de/rec/bib2/conf/ecai/Bravo-MarquezFP16.bib target=_blank rel=noopener>BibTex</a>, <a href=http://www.cs.waikato.ac.nz/~fbravoma/publications/ecai2016.pdf target=_blank rel=noopener>original paper</a></p></li><li><p><strong>PTCM</strong>: The Partitioned Tweet Centroid Model (PTCM) is an adaption of the TweetCentroidModel for distant supervision. As tweets and words are represented by the same feature vectors, a word-level classifier trained from a polarity lexicon and a corpus of unlabelled tweets can be used for classifying the sentiment of tweets represented by sparse feature vectors. In other words, the labelled word vectors correspond to lexicon-annotated training data for message-level polarity classification.
The model includes a simple modification to the tweet centroid model for increasing the number of labelled instances, yielding <em>partitioned tweet centroids</em>. This modification is based on partitioning the tweets associated with each word into smaller disjoint subsets of a fixed size. The method calculates one centroid per partition, which is labelled according to the lexicon.
<a href=http://dblp.uni-trier.de/rec/bib2/conf/webi/Bravo-MarquezFP16.bib target=_blank rel=noopener>BibTex</a>, <a href=https://www.cs.waikato.ac.nz/~fbravoma/publications/wi2016t.pdf target=_blank rel=noopener>original paper</a></p></li><li><p><strong>LexiconDistantSupervision</strong>: This is the most popular distant supervision approach for Twitter sentiment analysis. It takes a collection of unlabelled tweets and a polarity lexicon in arff format of positive and negative tokens. If a word from the lexicon is found, the tweet is labelled with the word&rsquo;s polarity. Tweets with both positive and negative words are discarded. The word used for labelling the tweet can be removed from the content. Emoticons are used as the default lexicon. <a href=http://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf target=_blank rel=noopener>original paper</a></p></li></ol><h3 id=tokenizers>Tokenizers</h3><ol><li><strong>TweetNLPTokenizer</strong>: a Twitter-specific String tokenizer based on the <a href=http://www.cs.cmu.edu/~ark/TweetNLP/ target=_blank rel=noopener>CMU Tweet NLP tool</a> that can be used with the existing <a href=http://weka.sourceforge.net/doc.dev/weka/filters/unsupervised/attribute/StringToWordVector.html target=_blank rel=noopener>StringWordToVector</a> Weka filter.</li></ol><h3 id=other-resources>Other Resources</h3><ol><li><p><strong>Datasets</strong>: The package provides some tweets annotated by affective values in gzipped <a href=http://weka.wikispaces.com/ARFF target=_blank rel=noopener>ARFF</a> format in $WEKA_HOME/packages/AffectiveTweets/data/. The default location for $WEKA_HOME is $HOME/wekafiles.</p></li><li><p><strong>Affective Lexicons</strong>: The package provides affective lexicons in <a href=http://weka.wikispaces.com/ARFF target=_blank rel=noopener>ARFF</a> format. These lexicons are located in $WEKA_HOME/packages/AffectiveTweets/lexicons/arff_lexicons/ and can be used with the <strong>TweetToInputLexiconFeatureVector</strong> filter.</p></li><li><p><strong>Pre-trained Word-Embeddings</strong>: The package provides a file with pre-trained word vectors trained with the <a href=https://code.google.com/archive/p/word2vec/ target=_blank rel=noopener>Word2Vec</a> tool in gzip compressed format. It is a tab separated file with the word in last column located in $WEKA_HOME/packages/AffectiveTweets/resources/w2v.twitter.edinburgh.100d.csv.gz. However, this is a toy example trained from a small collection of tweets. We recommend downloading <a href=https://github.com/felipebravom/AffectiveTweets/releases/download/1.0.0/w2v.twitter.edinburgh10M.400d.csv.gz target=_blank rel=noopener>w2v.twitter.edinburgh10M.400d.csv.gz</a>, which provides embeddings trained from 10 million tweets taken from the <a href=http://www.aclweb.org/anthology/W/W10/W10-0513.pdf target=_blank rel=noopener>Edinburgh corpus</a>. The parameters were calibrated for classifying words into emotions. More info in this <a href=http://www.cs.waikato.ac.nz/~fjb11/publications/wi2016a.pdf target=_blank rel=noopener>paper</a>.</p></li></ol><h2 id=documentation>Documentation</h2><p>The Java documentation is available <a href=https://felipebravom.github.io/AffectiveTweets/doc/index.html target=_blank rel=noopener>here</a>.</p><h2 id=team>Team</h2><h3 id=main-developer>Main Developer</h3><ul><li><a href=https://felipebravom.com/ target=_blank rel=noopener>Felipe Bravo-Marquez</a></li></ul><h2 id=contributors>Contributors</h2><ul><li><a href=http://saifmohammad.com/ target=_blank rel=noopener>Saif Mohammad</a></li><li><a href=http://www.cs.waikato.ac.nz/~eibe/ target=_blank rel=noopener>Eibe Frank</a></li><li><a href=https://www.cs.waikato.ac.nz/~bernhard/ target=_blank rel=noopener>Bernhard Pfahringer</a></li></ul><h2 id=contact>Contact</h2><ul><li>Email: fbravo at dcc.uchile.cl</li><li>If you have questions about Weka please refer to the Weka <a href=https://list.waikato.ac.nz/mailman/listinfo/wekalist target=_blank rel=noopener>mailing list</a>.</li></ul></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2022 Me. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.0047d4febf356e7f0b988e541f50b065.js></script>
<script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js type=module></script>
<script src=/en/js/wowchemy.min.51d2736755dc548e60c4649aaa3eeceb.js></script>
<script src=/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.b0d291ed6d27eacec233e6cf5204f99a.js type=module></script></body></html>